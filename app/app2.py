from flask import Flask, render_template, Response, jsonify
import cv2
import os
import threading
import torch
import numpy as np
from ultralytics import YOLO

app = Flask(__name__)

zone_coords = {
    # "1": [(16,19), (2578,15), (2564,1632), (13,1640) ]
    "1": [(2782,807), (3080,783), (3140,911), (2829,924)],
    "2": [(1550,878), (1791,876), (1836,951), (1572,955) ],
    "3": [(1593,1033),(1894,1020),(1929,1103),(1643,1107)],
    "4": [(869,1249),(1140,1161),(1337,1247),(1036,1389)]
}

# # --- YOLO ëª¨ë¸ (ì‚¬ëŒ íƒì§€ ì „ìš©) ---
# device = 'cuda' if torch.cuda.is_available() else 'cpu'
# print(f"ğŸ” Using device: {device}")
# model = YOLO("/workspace/wdtc/project/flask2/epoch40_4.engine").to(device)

# --- YOLO ëª¨ë¸ (ì‚¬ëŒ íƒì§€ ì „ìš©) ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ğŸ” Using device: {device}")
# .engineì€ .to(device) ë¶ˆê°€ â†’ predictì—ì„œ device ì§€ì •
DEVICE_ARG = 0 if device == 'cuda' else 'cpu'
# model = YOLO("/workspace/wdtc/project/flask2/yolov8n.pt", task="detect")
# model = YOLO("/workspace/wdtc/project/code/yolo11l.engine", task="detect")
model = YOLO("epoch40.pt", task="detect")

def infer(img, **kwargs):
    # ë‚´ë³´ë‚¸ ëª¨ë¸ì€ predictë§Œ ì§€ì›í•˜ê³ , ì—¬ê¸°ì„œ deviceë¥¼ ë„˜ê²¨ì•¼ í•¨
    return model.predict(img, device=DEVICE_ARG, **kwargs)

# --- ì˜ìƒ ê²½ë¡œ ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# video_path = os.path.join(BASE_DIR, "static", "videos", "E05_020.mp4")
video_path = os.path.join(BASE_DIR, "static", "videos", "sample3.mp4")

# --- ì „ì—­ ë³€ìˆ˜: êµ¬ì—­ë³„ ê°ì²´ íƒì§€ ê²°ê³¼ ---
zone_detections = {1: 0, 2: 0, 3: 0, 4: 0}
detection_lock = threading.Lock()

# --- ê²½ë³´ ì„ê³„ê°’ ---
WARNING_THRESHOLD = 5
DANGER_THRESHOLD = 7

def count_objects_in_zone(roi_frame):
    """ROI ë‚´ë¶€ ì‚¬ëŒ ìˆ˜ ì •í™•íˆ ì¹´ìš´íŠ¸"""
    # results = model(roi_frame, classes=[0], conf=0.25)
    results = infer(roi_frame, classes=[0], conf=0.25)
    if not results[0].boxes or len(results[0].boxes) == 0:
        return 0
    return len(results[0].boxes)  # ROI ì•ˆ ì‚¬ëŒ ìˆ˜ ê·¸ëŒ€ë¡œ ë°˜í™˜

def generate_frames(camera_id):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
    
    frame_skip = 5  # í”„ë ˆì„ ì„¤ì •
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue

        frame_count += 1
        if frame_count % frame_skip != 0:
            continue

        # MAIN í™”ë©´
        if str(camera_id) == 'main':
            img = frame.copy()
            for zone_id_str, coords in zone_coords.items():
                zone_id = int(zone_id_str)
                xs = [p[0] for p in coords]
                ys = [p[1] for p in coords]
                x1, y1, x2, y2 = min(xs), min(ys), max(xs), max(ys)
                
                pts = np.array(coords, np.int32)
                pts = pts.reshape((-1,1,2))  # OpenCV ë‹¤ê°í˜• í˜•ì‹

                # ë…¹ìƒ‰(0,255,0), ë‘ê»˜ 2ë¡œ í´ë¦¬ê³¤ ê·¸ë¦¬ê¸°
                cv2.polylines(frame, [pts], isClosed=True, color=(0,255,0), thickness=2)
                
                roi_frame = frame[y1:y2, x1:x2]

                with detection_lock:
                    zone_detections[zone_id] = count_objects_in_zone(roi_frame)

                # roi_results = model(roi_frame, classes=[0], conf=0.25)
                roi_results = infer(roi_frame, classes=[0], conf=0.25)
                try:
                    roi_img = roi_results[0].plot()
                except:
                    roi_img = roi_frame
                img[y1:y2, x1:x2] = roi_img

        # Zoneë§Œ ìŠ¤íŠ¸ë¦¬ë°
        else:
            camera_num = str(camera_id)
            if camera_num in zone_coords:
                coords = zone_coords[camera_num]
                xs = [p[0] for p in coords]
                ys = [p[1] for p in coords]
                x1, y1, x2, y2 = min(xs), min(ys), max(xs), max(ys)
              
                # 1) ì „ì²´ ì‚¬ê°í˜• í¬ë¡­
                cropped_frame = frame[y1:y2, x1:x2].copy()

                # 2) ë‹¤ê°í˜• ì¢Œí‘œë¥¼ cropped_frame ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
                poly_pts = np.array([(x - x1, y - y1) for x, y in coords], np.int32)
                poly_pts = poly_pts.reshape((-1, 1, 2))

                # 3) í¬ë¡­ ì´ë¯¸ì§€ í¬ê¸°ì™€ ê°™ì€ í¬ê¸°ì˜ ê²€ì • ë§ˆìŠ¤í¬ ìƒì„±
                mask = np.zeros(cropped_frame.shape[:2], dtype=np.uint8)

                # 4) ë‹¤ê°í˜• ì˜ì—­ë§Œ í°ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
                cv2.fillPoly(mask, [poly_pts], 255)

                # 5) ë§ˆìŠ¤í¬ ì ìš©í•´ì„œ ë‹¤ê°í˜• ì˜ì—­ë§Œ ì¶”ì¶œ
                masked_img = cv2.bitwise_and(cropped_frame, cropped_frame, mask=mask)

                with detection_lock:
                    zone_detections[int(camera_num)] = count_objects_in_zone(masked_img)

                # results = model(masked_img, classes=[0], conf=0.25)
                results = infer(masked_img, classes=[0], conf=0.25)
                try:
                    img = results[0].plot()
                except:
                    img = masked_img
            else:
                img = frame.copy()

        _, buffer = cv2.imencode('.jpg', img)
        frame_bytes = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

    cap.release()

# ------------------ Flask Routes ------------------
@app.route('/')
def index():
    return render_template('index.html', zone_coords=zone_coords)

@app.route('/camera/<camera_id>')
def camera_feed(camera_id):
    print(f"ì¹´ë©”ë¼ ìš”ì²­: {camera_id} (íƒ€ì…: {type(camera_id)})")
    return Response(generate_frames(camera_id),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/api/zone_detections')
def get_zone_detections():
    with detection_lock:
        return jsonify({
            'zones': zone_detections,
            'total_detections': sum(zone_detections.values()),
            'danger_zones': [zone_id for zone_id, count in zone_detections.items() if count >= DANGER_THRESHOLD],
            'thresholds': {
                'warning': WARNING_THRESHOLD,
                'danger': DANGER_THRESHOLD,
            }
        })

@app.route('/api/detection_stats')
def detection_stats():
    with detection_lock:
        return jsonify({
            'total_detections': sum(zone_detections.values()),
            'active_cameras': 5,  # MAIN + 4ê°œ ì¹´ë©”ë¼
            'zone_detections': zone_detections,
            'thresholds': {
                'warning': WARNING_THRESHOLD,
                'danger': DANGER_THRESHOLD,
            }
        })

@app.route('/api/alerts')
def get_alerts():
    with detection_lock:
        alerts = []
        for zone_id, count in zone_detections.items():
            if count >= DANGER_THRESHOLD:
                alerts.append(f"ğŸš¨ ZONE {zone_id}: {count}ëª… íƒì§€ - ìœ„í—˜ ìˆ˜ì¤€!")
            elif count >= WARNING_THRESHOLD:
                alerts.append(f"âš¡ ZONE {zone_id}: {count}ëª… íƒì§€ - ì£¼ì˜ í•„ìš”")
        
        if not alerts:
            alerts.append("âœ… ëª¨ë“  êµ¬ì—­ ì •ìƒ ìƒíƒœ")
            
        return jsonify({'alerts': alerts})

# ------------------ ì•± ì‹¤í–‰ ------------------
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=True)